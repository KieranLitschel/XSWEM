{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "global_explain_embedding_components.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FiWYLdj1_LE"
   },
   "source": [
    "This notebook explains how to use the global_plot_embedding_histogram and global_explain_embedding_components functions for a global explanation of your trained XSWEM model. As a pre-requisite to this notebook we would recommend reading section 4.1.1 of [Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms](https://arxiv.org/pdf/1805.09843.pdf), as this is where this method of explanation was originally proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can run this notebook in Google Colab by right-clicking on the badge below, and opening the link in a new tab.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KieranLitschel/XSWEM/blob/main/notebooks/global_explain_embedding_components.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install XSWEM and [Hugging Face datasets](https://github.com/huggingface/datasets)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install xswem\n",
    "!pip install datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKNLk6TCtk5b"
   },
   "source": [
    "First we load and prepare the dataset, and train the model. This is very similar code as in the train_xswem notebook, except we modify it for the [yelp_polarity dataset](https://huggingface.co/datasets/viewer/?dataset=yelp_polarity).\n",
    "\n",
    "From our experience using this method of global explainability, it seems to be important to use pre-trained GloVe embeddings and adapt the frozen embeddings. If we don't use them the model still performs similarly, but it is hard to see a pattern in the maximum values for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iK-SetLf1_LF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a8efc10e-6716-49d6-bcc0-2a28030082a6"
   },
   "source": [
    "## Download the GloVe embeddings. This is the \"Common Crawl (42B tokens, 1.9M \n",
    "## vocab, uncased, 300d vectors, 1.75 GB download)\" dataset, which you can \n",
    "## download here https://github.com/stanfordnlp/GloVe. We are hosting a copy\n",
    "## on Google Drive as downloading from the internet on Google Colab is slow.\n",
    "\n",
    "import os\n",
    "if not os.path.isfile(\"glove.42B.300d.txt\"):\n",
    "    !gdown --id 1LTAMRtx7VYKDI-7r6aG-t3E1nTHx7sG8\n",
    "    !unzip glove.42B.300d.zip\n",
    "\n",
    "## Make this notebook deterministic.\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "# Python RNG\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# TF RNG\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import random_seed\n",
    "random_seed.set_seed(RANDOM_SEED)\n",
    "\n",
    "## Import the necessary modules.\n",
    "\n",
    "from xswem.model import XSWEM\n",
    "from xswem.utils import prepare_embedding_weights_map_from_glove\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "## Load and shuffle the dataset. We keep 10% of the training set for validation.\n",
    "\n",
    "yelp_polarity = load_dataset('yelp_polarity')\n",
    "yelp_polarity = yelp_polarity.map(lambda row: {\n",
    "    \"text\": row[\"text\"].replace(\"\\\\n\",\"\\n\").replace(\"\\\\t\",\"\\t\"), \n",
    "    \"label\": row[\"label\"]})\n",
    "yelp_polarity = yelp_polarity.shuffle({\"train\":RANDOM_SEED,\"test\":RANDOM_SEED})\n",
    "yelp_polarity[\"train\"] = yelp_polarity[\"train\"].train_test_split(test_size=0.1,seed=RANDOM_SEED)\n",
    "yelp_polarity_train, yelp_polarity_valid = yelp_polarity[\"train\"][\"train\"], yelp_polarity[\"train\"][\"test\"]\n",
    "X, y = yelp_polarity_train[\"text\"], yelp_polarity_train[\"label\"]\n",
    "X_valid, y_valid = yelp_polarity_valid[\"text\"], yelp_polarity_valid[\"label\"]\n",
    "yelp_polarity_test = yelp_polarity[\"test\"]\n",
    "X_test, y_test = yelp_polarity_test[\"text\"], yelp_polarity_test[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "## Build the tokenizer.\n",
    "\n",
    "NUM_WORDS = 20000 # this means we only keep words where there are at least 50 examples\n",
    "FILTERS = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n0123456789'\n",
    "# Its important to set the oov_token to \"<unk>\"\" to match GloVe.\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<unk>\", filters=FILTERS)\n",
    "tokenizer.fit_on_texts(X)\n",
    "vocab_map = {i+1: tokenizer.index_word[i+1] for i in range(NUM_WORDS)}\n",
    "# this output map may seem slightly counterintuitive at first, as in the \n",
    "# yelp_polarity dataset, the label 0 means a text has negative polarity, and\n",
    "# 1 means positive polarity. But for our model we're using a sigmoid activation\n",
    "# function for the output layer as this is a binary classification problem, so \n",
    "# we only have only have one unit in the output layer, with an output of 0 \n",
    "# meaning negative polarity, and 1 meaning positive polarity. So our single \n",
    "# output unit identifies if a text has positive polarity, and is labelled as \n",
    "# such.\n",
    "output_map = {\n",
    "                0: \"Positive\"\n",
    "            }\n",
    "\n",
    "## Prepare the GloVe embeddings.\n",
    "\n",
    "vocab = vocab_map.values()\n",
    "embedding_weights_map = prepare_embedding_weights_map_from_glove(\"glove.42B.300d.txt\", vocab, verbose=1)\n",
    "\n",
    "## Build the dataset pipeline.\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_LABELS = len(output_map)\n",
    "\n",
    "train_dataset = Dataset.from_tensor_slices((X,y))\n",
    "valid_dataset = Dataset.from_tensor_slices((X_valid,y_valid))\n",
    "test_dataset = Dataset.from_tensor_slices((X_test,y_test))\n",
    "\n",
    "# Repeat and shuffle the train datasets.\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.shuffle(BATCH_SIZE*2)\n",
    "\n",
    "# Tokenize the text.\n",
    "# We only keep unique tokens as XSWEM is invariant to token frequency and order.\n",
    "tokenize = lambda text, label: (tf.py_function(lambda text: np.unique(tokenizer.texts_to_sequences([str(text.numpy())])[0]), inp=[text], Tout=tf.int32), label)\n",
    "train_dataset = train_dataset.map(tokenize,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.map(tokenize,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(tokenize,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Pre-fetch so that GPU spends less time waiting.\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Padded batch allows us to handle varying sentence lengths.\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE,padded_shapes=([None],[]))\n",
    "valid_dataset = valid_dataset.padded_batch(BATCH_SIZE,padded_shapes=([None],[]))\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE,padded_shapes=([None],[]))\n",
    "\n",
    "## Build the XSWEM model.\n",
    "model = XSWEM(300, \"sigmoid\", vocab_map, output_map, mask_zero=True, embedding_weights_map=embedding_weights_map, adapt_embeddings=True, freeze_embeddings=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "model.compile(optimizer, loss=\"binary_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "## Train XSWEM model.\n",
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=20, steps_per_epoch=10000, callbacks=[tf.keras.callbacks.EarlyStopping('val_accuracy', restore_best_weights=True)], verbose=2)\n",
    "\n",
    "## Test XSWEM model.\n",
    "model.evaluate(test_dataset)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Reusing dataset yelp_polarity (/root/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/2b33212d89209ed1ea0522001bccc5f5a5c920dd9c326f3c828e67a22c51a98c)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/2b33212d89209ed1ea0522001bccc5f5a5c920dd9c326f3c828e67a22c51a98c/cache-39795918bc77a6d3.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/2b33212d89209ed1ea0522001bccc5f5a5c920dd9c326f3c828e67a22c51a98c/cache-c503b806bebe9346.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/2b33212d89209ed1ea0522001bccc5f5a5c920dd9c326f3c828e67a22c51a98c/cache-86287e45fb253470.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/2b33212d89209ed1ea0522001bccc5f5a5c920dd9c326f3c828e67a22c51a98c/cache-771e79be57aea394.arrow\n",
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/2b33212d89209ed1ea0522001bccc5f5a5c920dd9c326f3c828e67a22c51a98c/cache-a022c17a5cfa2266.arrow and /root/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/2b33212d89209ed1ea0522001bccc5f5a5c920dd9c326f3c828e67a22c51a98c/cache-94c22adca4d296ff.arrow\n",
      "1917495it [00:47, 40194.54it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:683 words had no provided weights in embedding_weights_map so their embedding's were initialized randomly\n",
      "Epoch 1/20\n",
      "10000/10000 - 203s - loss: 0.3883 - accuracy: 0.8225 - val_loss: 0.2892 - val_accuracy: 0.8777\n",
      "Epoch 2/20\n",
      "10000/10000 - 199s - loss: 0.2654 - accuracy: 0.8880 - val_loss: 0.2496 - val_accuracy: 0.8963\n",
      "Epoch 3/20\n",
      "10000/10000 - 199s - loss: 0.2338 - accuracy: 0.9028 - val_loss: 0.2266 - val_accuracy: 0.9062\n",
      "Epoch 4/20\n",
      "10000/10000 - 200s - loss: 0.2196 - accuracy: 0.9098 - val_loss: 0.2155 - val_accuracy: 0.9112\n",
      "Epoch 5/20\n",
      "10000/10000 - 199s - loss: 0.2111 - accuracy: 0.9138 - val_loss: 0.2301 - val_accuracy: 0.9032\n",
      "1188/1188 [==============================] - 22s 18ms/step - loss: 0.2106 - accuracy: 0.9131\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.21059906482696533, 0.9131052494049072]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4qKnfDU7cCR"
   },
   "source": [
    "We plot a histogram of the component values, and observe that our model has learnt sparse embeddings, with most values centred around 0 and some very large values. This is the same pattern as observed in figure 1 of the [original paper](https://arxiv.org/pdf/1805.09843.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1s-wp-fhu9Ce",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "outputId": "9d15010e-a26c-4e70-a54a-82a11d560969"
   },
   "source": [
    "model.global_plot_embedding_histogram(adapt_embeddings=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnXgtQ7p72Rt"
   },
   "source": [
    "Below we show the results of our explainabiity function. This determines the top five words with the largest values for each component of the embeddings, and is equivalent to table 3 in the original paper. We label the columns of the table with the index of the component in the embedding vector.\r\n",
    "\r\n",
    "A lot of the components appear to be quite noisy, with no clear relevance to the classification task. We show the first 10 components here to demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lKAaFikuwVVJ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "outputId": "44c2854e-5f5e-402a-a59d-0a628436b505"
   },
   "source": [
    "global_explained_embedding_components = model.global_explain_embedding_components(adapt_embeddings=True)\r\n",
    "global_explained_embedding_components.iloc[:, :10]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quel</td>\n",
       "      <td>chicken</td>\n",
       "      <td>sip</td>\n",
       "      <td>pouvez</td>\n",
       "      <td>bulb</td>\n",
       "      <td>steam</td>\n",
       "      <td>seit</td>\n",
       "      <td>directv</td>\n",
       "      <td>nuong</td>\n",
       "      <td>countertop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panko</td>\n",
       "      <td>latex</td>\n",
       "      <td>fresh</td>\n",
       "      <td>tacos</td>\n",
       "      <td>bible</td>\n",
       "      <td>plates</td>\n",
       "      <td>whey</td>\n",
       "      <td>mbps</td>\n",
       "      <td>android</td>\n",
       "      <td>dispenser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sa</td>\n",
       "      <td>daal</td>\n",
       "      <td>grub</td>\n",
       "      <td>albacore</td>\n",
       "      <td>ce</td>\n",
       "      <td>cake</td>\n",
       "      <td>cholesterol</td>\n",
       "      <td>dish</td>\n",
       "      <td>ipad</td>\n",
       "      <td>counter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sore</td>\n",
       "      <td>masks</td>\n",
       "      <td>smoothie</td>\n",
       "      <td>michelada</td>\n",
       "      <td>parts</td>\n",
       "      <td>birthday</td>\n",
       "      <td>shiitake</td>\n",
       "      <td>imax</td>\n",
       "      <td>markup</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>offensive</td>\n",
       "      <td>flags</td>\n",
       "      <td>sorbet</td>\n",
       "      <td>chaque</td>\n",
       "      <td>puzzle</td>\n",
       "      <td>bikes</td>\n",
       "      <td>poultry</td>\n",
       "      <td>pedicure</td>\n",
       "      <td>kindle</td>\n",
       "      <td>optical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0        1         2  ...         7        8           9\n",
       "Word Rank                                ...                               \n",
       "1               quel  chicken       sip  ...   directv    nuong  countertop\n",
       "2              panko    latex     fresh  ...      mbps  android   dispenser\n",
       "3                 sa     daal      grub  ...      dish     ipad     counter\n",
       "4               sore    masks  smoothie  ...      imax   markup      gender\n",
       "5          offensive    flags    sorbet  ...  pedicure   kindle     optical\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QD_id2r-RZf_"
   },
   "source": [
    "There are some components though which really seem to be capturing a much clearer polarity, but note there is often still some noise. For example the components below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "jvrOcD7TRYHA",
    "outputId": "f7a23368-44bc-4150-b8b1-d5536b8b2cb8"
   },
   "source": [
    "clear_polarity = [37, 60, 159]\r\n",
    "global_explained_embedding_components.iloc[:, clear_polarity]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>37</th>\n",
       "      <th>60</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negligent</td>\n",
       "      <td>vampires</td>\n",
       "      <td>took</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resigned</td>\n",
       "      <td>rudest</td>\n",
       "      <td>hated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wanton</td>\n",
       "      <td>pitchers</td>\n",
       "      <td>teased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unoccupied</td>\n",
       "      <td>dirtiest</td>\n",
       "      <td>ended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lethargic</td>\n",
       "      <td>nastiest</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  37        60         159\n",
       "Word Rank                                 \n",
       "1           negligent  vampires       took\n",
       "2            resigned    rudest      hated\n",
       "3              wanton  pitchers     teased\n",
       "4          unoccupied  dirtiest      ended\n",
       "5           lethargic  nastiest  offensive"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 12
    }
   ]
  }
 ]
}